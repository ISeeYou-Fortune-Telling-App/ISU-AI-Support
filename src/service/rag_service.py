"""
Service Layer - X·ª≠ l√Ω logic nghi·ªáp v·ª• ch√≠nh c·ªßa h·ªá th·ªëng RAG
Ch·ª©a t·∫•t c·∫£ logic x·ª≠ l√Ω RAG, kh·ªüi t·∫°o v√† t√¨m ki·∫øm
"""

import os
import json
from typing import Optional, List
from lightrag import LightRAG, QueryParam
from ingestion import initialize_rag, index_file
from util.text_search_util import TextSearchUtil


class RAGService:
    """
    L·ªõp d·ªãch v·ª• ƒë·ªÉ qu·∫£n l√Ω c√°c ho·∫°t ƒë·ªông c·ªßa h·ªá th·ªëng RAG
    ƒê√¢y l√† "b·ªô n√£o" ch√≠nh x·ª≠ l√Ω t·∫•t c·∫£ logic nghi·ªáp v·ª•
    """
    
    def __init__(self, data_path: str = "../../data/data.txt", data_path_json: str = "../../data/data.json"):
        self.data_path = data_path           # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file d·ªØ li·ªáu text
        self.data_path_json = data_path_json # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file d·ªØ li·ªáu JSON
        self.data_files = [data_path, data_path_json]  # Danh s√°ch t·∫•t c·∫£ files c·∫ßn index
        self.rag = None                      # ƒê·ªëi t∆∞·ª£ng RAG (ban ƒë·∫ßu ch∆∞a c√≥)
        self.raw_text: Optional[str] = None  # VƒÉn b·∫£n d·ª± ph√≤ng n·∫øu RAG l·ªói
        self.indexing_complete: bool = False # Tr·∫°ng th√°i ƒë√°nh ch·ªâ m·ª•c

    async def initialize(self, force_reindex: bool = False):
        """
        Kh·ªüi t·∫°o v√† ƒë√°nh ch·ªâ m·ª•c d·ªØ li·ªáu t·ª´ nhi·ªÅu files kh√¥ng ƒë·ªìng b·ªô. 
        S·ª≠ d·ª•ng h√†m index_file v·ªõi th·ª≠ l·∫°i nhi·ªÅu l·∫ßn,
        v√† d·ª± ph√≤ng l∆∞u vƒÉn b·∫£n th√¥ n·∫øu ƒë√°nh ch·ªâ m·ª•c th·∫•t b·∫°i.
        """
        # B∆∞·ªõc 1: Ki·ªÉm tra t·∫•t c·∫£ files d·ªØ li·ªáu c√≥ t·ªìn t·∫°i kh√¥ng
        missing_files = []
        for file_path in self.data_files:
            if not os.path.exists(file_path):
                missing_files.append(file_path)
        
        if missing_files:
            raise FileNotFoundError(f"Data files not found: {missing_files}")

        # B∆∞·ªõc 2: Ki·ªÉm tra files c√≥ r·ªóng kh√¥ng
        empty_files = []
        for file_path in self.data_files:
            if os.path.getsize(file_path) == 0:
                empty_files.append(file_path)
        
        if empty_files:
            raise ValueError(f"Data files are empty: {empty_files}")

        # B∆∞·ªõc 3: Kh·ªüi t·∫°o RAG n·∫øu ch∆∞a c√≥ ho·∫∑c b·∫Øt bu·ªôc t·∫°o l·∫°i
        if self.rag is None or force_reindex:
            print("Initializing RAG system...")
            # Th·ª≠ kh·ªüi t·∫°o h·ªá th·ªëng RAG
            try:
                self.rag = await initialize_rag()
            except Exception as e:
                print(f"initialize_rag failed: {e}")
                # Gi·ªØ self.rag = None v√† ti·∫øp t·ª•c chu·∫©n b·ªã d·ª± ph√≤ng
                self.rag = None

            # B∆∞·ªõc 4: ƒê√°nh ch·ªâ m·ª•c t·∫•t c·∫£ files
            print(f"Indexing data from {len(self.data_files)} files...")
            if self.rag is not None:
                indexed_files = []
                failed_files = []
                
                for file_path in self.data_files:
                    print(f"Indexing {file_path}...")
                    last_exc = None
                    
                    # Th·ª≠ 3 l·∫ßn cho m·ªói file
                    for attempt in range(1, 4):
                        try:
                            print(f"  Attempt {attempt}/3 for {os.path.basename(file_path)}...")
                            
                            # X·ª≠ l√Ω file theo ƒë·ªãnh d·∫°ng
                            if file_path.endswith('.json'):
                                await self._index_json_file(self.rag, file_path)
                            else:
                                await index_file(self.rag, file_path)
                            
                            print(f"  ‚úÖ Successfully indexed {os.path.basename(file_path)}")
                            indexed_files.append(file_path)
                            last_exc = None
                            break
                        except Exception as e:
                            print(f"  ‚ùå Attempt {attempt} failed for {os.path.basename(file_path)}: {e}")
                            last_exc = e

                    # N·∫øu file th·∫•t b·∫°i sau t·∫•t c·∫£ attempts
                    if last_exc:
                        print(f"Failed to index {file_path} after retries: {last_exc}")
                        failed_files.append(file_path)

                # B√°o c√°o k·∫øt qu·∫£ indexing
                print(f"Indexing summary:")
                print(f"  ‚úÖ Successfully indexed: {len(indexed_files)} files")
                print(f"  ‚ùå Failed to index: {len(failed_files)} files")
                
                if indexed_files:
                    print("Successfully indexed files:")
                    for file_path in indexed_files:
                        print(f"  - {os.path.basename(file_path)}")
                
                if failed_files:
                    print("Failed files:")
                    for file_path in failed_files:
                        print(f"  - {os.path.basename(file_path)}")
                    
                    # Chu·∫©n b·ªã vƒÉn b·∫£n d·ª± ph√≤ng t·ª´ t·∫•t c·∫£ files c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c
                    self._prepare_fallback_text()

                    # Th·ª≠ ch√®n tr·ª±c ti·∫øp vƒÉn b·∫£n d·ª± ph√≤ng
                    try:
                        if self.rag is not None and self.raw_text:
                            await self.rag.ainsert(self.raw_text)
                            print("Fallback raw indexing complete!")
                            self.indexing_complete = True
                    except Exception as e2:
                        print(f"Fallback ainsert also failed: {e2}. Will use local text search fallback.")
                        self.indexing_complete = False
                else:
                    # T·∫•t c·∫£ files ƒë·ªÅu indexed th√†nh c√¥ng
                    self.indexing_complete = True
                    print("üéâ All files indexed successfully!")
            else:
                # Kh√¥ng th·ªÉ kh·ªüi t·∫°o RAG; t·∫£i vƒÉn b·∫£n th√¥ ƒë·ªÉ t√¨m ki·∫øm c·ª•c b·ªô
                self._prepare_fallback_text()
                print("Loaded raw text from all files for local fallback search.")
                self.indexing_complete = False

        # ƒê√°nh d·∫•u ho√†n th√†nh ƒë√°nh ch·ªâ m·ª•c n·∫øu rag t·ªìn t·∫°i v√† kh√¥ng c√≥ l·ªói
        if self.rag is not None and self.indexing_complete is False:
            # N·∫øu rag t·ªìn t·∫°i v√† ch∆∞a ƒë·∫∑t indexing_complete, ƒë·∫∑t True
            self.indexing_complete = True
        return self.rag

    async def _index_json_file(self, rag: LightRAG, file_path: str) -> None:
        """
        ƒê√°nh ch·ªâ m·ª•c file JSON b·∫±ng c√°ch chuy·ªÉn ƒë·ªïi th√†nh text
        
        Args:
            rag: LightRAG instance
            file_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file JSON
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                json_text = f.read()  # ƒê·ªçc tr·ª±c ti·∫øp text thay v√¨ parse JSON
        
            # ƒê√°nh ch·ªâ m·ª•c text JSON
            await rag.ainsert(input=json_text)
            
        except Exception as e:
            print(f"Error indexing JSON file {file_path}: {e}")
            raise e

    def _prepare_fallback_text(self):
        """
        Chu·∫©n b·ªã vƒÉn b·∫£n d·ª± ph√≤ng t·ª´ t·∫•t c·∫£ files ƒë·ªÉ t√¨m ki·∫øm c·ª•c b·ªô
        """
        all_text = []
        
        for file_path in self.data_files:
            try:
                # ƒê·ªçc t·∫•t c·∫£ files nh∆∞ text, kh√¥ng ph√¢n bi·ªát JSON hay text
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                all_text.append(f"=== Data t·ª´ {os.path.basename(file_path)} ===\n{content}\n")
                    
            except Exception as e:
                print(f"Failed to load {file_path} for fallback: {e}")
        
        self.raw_text = "\n\n".join(all_text) if all_text else None

    async def get_answer(self, question: str, mode: str = "mix", top_k: int = 5, force_reindex: bool = False) -> str:
        """
        X·ª≠ l√Ω c√¢u h·ªèi v√† tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi
        ƒê√¢y l√† h√†m ch√≠nh ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
        """
        # B∆∞·ªõc 1: Th·ª≠ kh·ªüi t·∫°o RAG (c√≥ th·ªÉ ƒë·∫∑t self.raw_text n·∫øu d√πng d·ª± ph√≤ng)
        try:
            await self.initialize(force_reindex=force_reindex)
        except Exception as e:
            print(f"RAG initialization failed in get_answer: {e}")

        # B∆∞·ªõc 2: N·∫øu RAG c√≥ s·∫µn, th·ª≠ s·ª≠ d·ª•ng n√≥
        if self.rag is not None:
            query_param = QueryParam(
                mode=mode,              # Ch·∫ø ƒë·ªô t√¨m ki·∫øm
                top_k=top_k,           # S·ªë k·∫øt qu·∫£ t·ªëi ƒëa
                enable_rerank=False    # Kh√¥ng s·∫Øp x·∫øp l·∫°i k·∫øt qu·∫£
            )
            try:
                return await self.rag.aquery(question, param=query_param)
            except Exception as e:
                print(f"RAG query failed: {e}")

        # B∆∞·ªõc 3: D·ª± ph√≤ng: t√¨m ki·∫øm c·ª•c b·ªô tr√™n vƒÉn b·∫£n th√¥
        print("Using local fallback search...")
        if not self.raw_text:
            self._prepare_fallback_text()
            if not self.raw_text:
                return "Sorry, I'm not able to provide an answer to that question.[no-data]"

        # S·ª≠ d·ª•ng utility class ƒë·ªÉ t√¨m ki·∫øm
        text_search = TextSearchUtil()
        return text_search.local_search(self.raw_text, question, top_k)

    def get_status(self) -> dict:
        """
        L·∫•y tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa h·ªá th·ªëng RAG
        """
        return {
            "rag_initialized": self.rag is not None,
            "indexing_complete": self.indexing_complete,
            "data_files": self.data_files,
            "data_files_count": len(self.data_files),
            "data_path": self.data_path,  # Backward compatibility
            "has_fallback_text": self.raw_text is not None
        }

    async def update_data_txt(self, file_content: bytes, force_reindex: bool = True) -> dict:
        """
        C·∫≠p nh·∫≠t file data.txt v·ªõi n·ªôi dung m·ªõi
        
        Args:
            file_content: N·ªôi dung file m·ªõi (bytes)
            force_reindex: C√≥ t·ª± ƒë·ªông reindex sau khi update kh√¥ng
            
        Returns:
            dict: K·∫øt qu·∫£ c·ªßa qu√° tr√¨nh c·∫≠p nh·∫≠t
        """
        try:
            # Ghi n·ªôi dung m·ªõi v√†o data.txt
            with open(self.data_path, 'wb') as f:
                f.write(file_content)
            
            print(f"Updated data.txt with {len(file_content)} bytes")
            
            # T·ª± ƒë·ªông reindex n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
            if force_reindex:
                await self.initialize(force_reindex=True)
                
            return {
                "status": "success",
                "message": f"Successfully updated data.txt",
                "file_size": len(file_content),
                "reindexed": force_reindex
            }
            
        except Exception as e:
            print(f"Error updating data.txt: {e}")
            return {
                "status": "error", 
                "message": f"Failed to update data.txt: {str(e)}"
            }

    async def update_data_json(self, file_content: bytes, force_reindex: bool = True) -> dict:
        """
        C·∫≠p nh·∫≠t file data.json v·ªõi n·ªôi dung m·ªõi
        
        Args:
            file_content: N·ªôi dung file m·ªõi (bytes)
            force_reindex: C√≥ t·ª± ƒë·ªông reindex sau khi update kh√¥ng
            
        Returns:
            dict: K·∫øt qu·∫£ c·ªßa qu√° tr√¨nh c·∫≠p nh·∫≠t
        """
        try:
            # Ghi n·ªôi dung m·ªõi v√†o data.json
            with open(self.data_path_json, 'wb') as f:
                f.write(file_content)
            
            print(f"Updated data.json with {len(file_content)} bytes")
            
            # T·ª± ƒë·ªông reindex n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
            if force_reindex:
                await self.initialize(force_reindex=True)
                
            return {
                "status": "success",
                "message": f"Successfully updated data.json",
                "file_size": len(file_content),
                "reindexed": force_reindex
            }
            
        except Exception as e:
            print(f"Error updating data.json: {e}")
            return {
                "status": "error",
                "message": f"Failed to update data.json: {str(e)}"
            }
